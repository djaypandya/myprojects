{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIT720 Assignment 2\n",
    "<p>*Student Name: Dhananjay Pandya*</p>\n",
    "*Student Number: 218202943*\n",
    "## All packages required for this assignment are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Binary Classification\n",
    "### 1.1: Data Munging\n",
    "Objectives: \n",
    "1. Read the training & testing data\n",
    "2. Print the number of features\n",
    "3. For the data label, print the number of 1's and 0's in the training and testing data\n",
    "4. Comment on the class distribution. Is it balanced or unbalanced?\n",
    "5. Print the number of features with missing entries\n",
    "6. Fill the missing entries. For filling any feature, you can use either mean or median value of the feature values from observed entries.\n",
    "7. Normalize the training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective 1: Read the training and testing data\n",
    "\n",
    "testWbcd = pd.read_csv('test_wbcd.csv',delimiter=\",\",header=0)\n",
    "trainWbcd = pd.read_csv('train_wbcd.csv',delimiter=\",\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Features: 30\n"
     ]
    }
   ],
   "source": [
    "# Objective 2: Print the number of features\n",
    "\n",
    "print('Total Number of Features: {}'.format(trainWbcd.shape[1]-2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>To complete objective 3 and 4, I first need to define what 1's and 0's are in this dataset. Upon inspection the original data labels are NOT 1's and 0's. Instead they are 'B' (benign) and 'M' (malignant).</p>\n",
    "<p>**For my assignment, I am assuming that 'B' is a 0 and 'M is a 1**</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of zeros in testing data: 14\n",
      "Total Number of ones in testing data: 6\n",
      "Total Number of zeros in training data: 58\n",
      "Total Number of ones in training data: 42\n"
     ]
    }
   ],
   "source": [
    "# Objective 3: For the data label, print the number of 1's and 0's in the training and testing data\n",
    "\n",
    "testBenign = 0\n",
    "testMalignant = 0\n",
    "\n",
    "for i in range(0,testWbcd.shape[0]):\n",
    "    if testWbcd.iloc[i,1]=='B':\n",
    "        testBenign = testBenign+1\n",
    "    elif testWbcd.iloc[i,1]=='M':\n",
    "        testMalignant = testMalignant+1\n",
    "        \n",
    "trainBenign = 0\n",
    "trainMalignant = 0\n",
    "\n",
    "for i in range(0,trainWbcd.shape[0]):\n",
    "    if trainWbcd.iloc[i,1]=='B':\n",
    "        trainBenign = trainBenign+1\n",
    "    elif trainWbcd.iloc[i,1]=='M':\n",
    "        trainMalignant = trainMalignant+1\n",
    "        \n",
    "print('Total Number of zeros in testing data: {}'.format(testBenign))\n",
    "print('Total Number of ones in testing data: {}'.format(testMalignant))\n",
    "\n",
    "print('Total Number of zeros in training data: {}'.format(trainBenign))\n",
    "print('Total Number of ones in training data: {}'.format(trainMalignant))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective 4: Comment on the class distribution. Is it balanced or unbalanced?**\n",
    "\n",
    "The concept of balanced and unbalanced class distribution apply to training data, because this is the data that the machine learns from. In this case the training data is balanced fairly well because the number of tuples with label 0 (benign) is roughly equal to the number of tuples with label 1 (malignant)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features with missing entries in test data: 1\n",
      "Number of features with missing entries in train data: 1\n"
     ]
    }
   ],
   "source": [
    "# Objective 5: Print the number of features with missing entries\n",
    "\n",
    "count_test_missing = 0\n",
    "for i in range(0,testWbcd.shape[1]):\n",
    "    if (testWbcd.isnull().sum())[i]>0:\n",
    "        count_test_missing+=1\n",
    "\n",
    "count_train_missing = 0\n",
    "for i in range(0,trainWbcd.shape[1]):\n",
    "    if (trainWbcd.isnull().sum())[i]>0:\n",
    "        count_train_missing+=count_train_missing+1\n",
    "        \n",
    "print('Number of features with missing entries in test data: {}'.format(count_test_missing))\n",
    "print('Number of features with missing entries in train data: {}'.format(count_train_missing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective 6: Fill the missing entries. For filling any feature, you can use either mean or median value of the feature values from observed entries.**\n",
    "\n",
    "First, we need to decide whether to use the mean or median value. For this, I am using histograms of each feature to understand the distribution of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[<matplotlib.axes._subplots.AxesSubplot object at 0x1a14d642b0>]]\n",
      "[[<matplotlib.axes._subplots.AxesSubplot object at 0x1a14c635f8>]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(0,testWbcd.shape[1]):\n",
    "    if (testWbcd.isnull().sum())[i]>0:\n",
    "        print(testWbcd.hist(column=testWbcd.columns.values[i]))\n",
    "for i in range(0,trainWbcd.shape[1]):\n",
    "    if (trainWbcd.isnull().sum())[i]>0:\n",
    "        print(trainWbcd.hist(column=trainWbcd.columns.values[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both distribution are skewed to the right. As a result, the mean is not a good measure of central tendency for this feature.\n",
    "\n",
    "*Therefore, I am using the median to replace null values for this feature in the training and testing dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_to_replace_nan = 0\n",
    "for i in range(0,testWbcd.shape[1]):\n",
    "    if (testWbcd.isnull().sum())[i]>0:\n",
    "        val_to_replace_nan = testWbcd.iloc[:,i].median()\n",
    "        testWbcd.iloc[:,i].fillna(val_to_replace_nan, inplace=True)\n",
    "        \n",
    "for i in range(0,trainWbcd.shape[1]):\n",
    "    if (trainWbcd.isnull().sum())[i]>0:\n",
    "        val_to_replace_nan = trainWbcd.iloc[:,i].median()\n",
    "        trainWbcd.iloc[:,i].fillna(val_to_replace_nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective 7: Normalize the training and testing data\n",
    "\n",
    "# Replacing 'B' and 'M' with 0 and 1 prior to normalizing data\n",
    "testWbcd['Diagnosis'].replace(to_replace='B',value=0,inplace=True)\n",
    "testWbcd['Diagnosis'].replace(to_replace='M',value=1,inplace=True)   \n",
    "\n",
    "trainWbcd['Diagnosis'].replace(to_replace='B',value=0,inplace=True)\n",
    "trainWbcd['Diagnosis'].replace(to_replace='M',value=1,inplace=True)\n",
    "\n",
    "# Normalizing the data\n",
    "testNorm = scale(testWbcd.iloc[:,2:])\n",
    "trainNorm = scale(trainWbcd.iloc[:,2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2: Logistic Regression\n",
    "Objective: Train logistic regression models with L1 regularization and L2 regularization using alpha = 0.1 and lambda = 0.1. Report accuracy, precision, recall, f1-score and print the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 Accuracy: 0.9\n",
      "L1 Precision: 0.8809523809523809\n",
      "L1 Recall: 0.8809523809523809\n",
      "L1 F1-Score: 0.8809523809523809\n",
      "L1 Confusion Matrix:\n",
      "[[13  1]\n",
      " [ 1  5]]\n",
      "L2 Accuracy: 0.9\n",
      "L2 Precision: 0.8809523809523809\n",
      "L2 Recall: 0.8809523809523809\n",
      "L2 F1-Score: 0.8809523809523809\n",
      "L2 Confusion Matrix:\n",
      "[[13  1]\n",
      " [ 1  5]]\n"
     ]
    }
   ],
   "source": [
    "alpha_val=0.1\n",
    "logistic_lasso = LogisticRegression(penalty='l1', C=1/alpha_val)\n",
    "logistic_lasso.fit(trainNorm,trainWbcd['Diagnosis'])\n",
    "logistic_lasso_predict = logistic_lasso.predict(testNorm)\n",
    "print(('L1 Accuracy: {}').format(accuracy_score(testWbcd['Diagnosis'],logistic_lasso_predict)))\n",
    "print(('L1 Precision: {}').format(precision_score(testWbcd['Diagnosis'],logistic_lasso_predict,average='macro')))\n",
    "print(('L1 Recall: {}').format(recall_score(testWbcd['Diagnosis'],logistic_lasso_predict,average='macro')))\n",
    "print(('L1 F1-Score: {}').format(f1_score(testWbcd['Diagnosis'],logistic_lasso_predict,average='macro')))\n",
    "print('L1 Confusion Matrix:')\n",
    "print(confusion_matrix(testWbcd['Diagnosis'],logistic_lasso_predict))\n",
    "\n",
    "lambda_val=0.1\n",
    "logistic_ridge = LogisticRegression(penalty='l2', C=1/lambda_val)\n",
    "logistic_ridge.fit(trainNorm,trainWbcd['Diagnosis'])\n",
    "logistic_ridge_predict = logistic_ridge.predict(testNorm)\n",
    "print(('L2 Accuracy: {}').format(accuracy_score(testWbcd['Diagnosis'],logistic_ridge_predict)))\n",
    "print(('L2 Precision: {}').format(precision_score(testWbcd['Diagnosis'],logistic_ridge_predict,average='macro')))\n",
    "print(('L2 Recall: {}').format(recall_score(testWbcd['Diagnosis'],logistic_ridge_predict,average='macro')))\n",
    "print(('L2 F1-Score: {}').format(f1_score(testWbcd['Diagnosis'],logistic_ridge_predict,average='macro')))\n",
    "print('L2 Confusion Matrix:')\n",
    "print(confusion_matrix(testWbcd['Diagnosis'],logistic_ridge_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2: Choosing the best hyperparameter\n",
    "Objectives:\n",
    "1. For L1 model, choose the best alpha value from the following set: {0.1,1,3,10,33,100,333,1000, 3333, 10000, 33333}.\n",
    "2. For L2 model, choose the best lambda value from the following set: {0.001, 0.003, 0.01, 0.03, 0.1,0.3,1,3,10,33}.\n",
    "3. Discuss if there is any sign of underfitting or overfitting with appropriate reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 Accuracy: 0.8\n",
      "L1 Precision: 0.7708333333333333\n",
      "L1 Confusion Matrix:\n",
      "[[11  3]\n",
      " [ 1  5]]\n",
      "The best feature is: f22\n",
      "The 2nd best feature is: f23\n",
      "The 3rd best feature is: f24\n",
      "The 4th best feature is: f4\n",
      "The 5th best feature is: f5\n"
     ]
    }
   ],
   "source": [
    "# Objective 1: For L1 model, choose the best alpha value from the following set: {0.1,1,3,10,33,100,333,1000, 3333, 10000, 33333}.\n",
    "\n",
    "alpha_vals=[0.1,1,3,10,33,100,333,1000, 3333, 10000, 33333]\n",
    "predictors=list(trainWbcd.columns.values)[2:32]\n",
    "model_acc =0\n",
    "l1_acc=np.empty((len(alpha_vals),0))\n",
    "\n",
    "for a in alpha_vals:\n",
    "    for i in range(0,100):\n",
    "        train,test=train_test_split(trainWbcd,test_size=0.3)\n",
    "        enet = SGDClassifier(loss='log', penalty='l1', alpha=a, l1_ratio=1, max_iter=1000)\n",
    "        enet.fit(train[predictors],train['Diagnosis'].values.reshape((train['Diagnosis'].shape[0],)))\n",
    "        y_predict = enet.predict(test[predictors])\n",
    "        y_predict = np.reshape(y_predict,np.shape(test['Diagnosis']))\n",
    "        model_acc += accuracy_score(y_predict,test['Diagnosis'].values.reshape((test['Diagnosis'].shape[0],)))\n",
    "    model_acc /= 100\n",
    "    l1_acc=np.append(l1_acc,model_acc)\n",
    "    \n",
    "    if a==alpha_vals[len(alpha_vals)-1]:\n",
    "        max_index_l1 = np.argmax(l1_acc)\n",
    "        best_alpha = alpha_vals[max_index_l1]\n",
    "        logistic_lasso = LogisticRegression(penalty='l1', C=1/best_alpha)\n",
    "        logistic_lasso.fit(trainWbcd[predictors],trainWbcd['Diagnosis'])\n",
    "        logistic_lasso_predict = logistic_lasso.predict(testWbcd[predictors])\n",
    "        print(('L1 Accuracy: {}').format(accuracy_score(testWbcd['Diagnosis'],logistic_lasso_predict)))\n",
    "        print(('L1 Precision: {}').format(precision_score(testWbcd['Diagnosis'],logistic_lasso_predict,average='macro')))\n",
    "        print('L1 Confusion Matrix:')\n",
    "        print(confusion_matrix(testWbcd['Diagnosis'],logistic_lasso_predict))\n",
    "        coef = logistic_lasso.coef_\n",
    "        desc_coef = -np.sort(-coef)\n",
    "        print(('The best feature is: {}').format(predictors[(np.where(coef==desc_coef[:,0]))[1][0]]))\n",
    "        print(('The 2nd best feature is: {}').format(predictors[(np.where(coef==desc_coef[:,1]))[1][0]]))\n",
    "        print(('The 3rd best feature is: {}').format(predictors[(np.where(coef==desc_coef[:,2]))[1][0]]))\n",
    "        print(('The 4th best feature is: {}').format(predictors[(np.where(coef==desc_coef[:,3]))[1][0]]))\n",
    "        print(('The 5th best feature is: {}').format(predictors[(np.where(coef==desc_coef[:,4]))[1][0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 Accuracy: 0.85\n",
      "L2 Precision: 0.8186813186813187\n",
      "L2 Confusion Matrix:\n",
      "[[12  2]\n",
      " [ 1  5]]\n",
      "The best feature is: f22\n",
      "The 2nd best feature is: f23\n",
      "The 3rd best feature is: f27\n",
      "The 4th best feature is: f26\n",
      "The 5th best feature is: f13\n"
     ]
    }
   ],
   "source": [
    "# Objective 2: For L2 model, choose the best lambda value from the following set: {0.001, 0.003, 0.01, 0.03, 0.1,0.3,1,3,10,33}.\n",
    "\n",
    "lambda_vals=[0.001, 0.003, 0.01, 0.03, 0.1,0.3,1,3,10,33]\n",
    "predictors=list(trainWbcd.columns.values)[2:32]\n",
    "model_acc =0\n",
    "l2_acc=np.empty((len(lambda_vals),0))\n",
    "\n",
    "for l in lambda_vals:\n",
    "    for i in range(0,100):\n",
    "        train,test=train_test_split(trainWbcd,test_size=0.3)\n",
    "        enet = SGDClassifier(loss='log', penalty='l2', alpha=l, l1_ratio=0, max_iter=1000)\n",
    "        enet.fit(train[predictors],train['Diagnosis'].values.reshape((train['Diagnosis'].shape[0],)))\n",
    "        y_predict = enet.predict(test[predictors])\n",
    "        y_predict = np.reshape(y_predict,np.shape(test['Diagnosis']))\n",
    "        model_acc += accuracy_score(y_predict,test['Diagnosis'].values.reshape((test['Diagnosis'].shape[0],)))\n",
    "    model_acc /= 100\n",
    "    l2_acc=np.append(l2_acc,model_acc)\n",
    "    \n",
    "    if l==lambda_vals[len(lambda_vals)-1]:\n",
    "        max_index_l2 = np.argmax(l2_acc)\n",
    "        best_lambda = lambda_vals[max_index_l2]\n",
    "        logistic_ridge = LogisticRegression(penalty='l2', C=1/best_lambda)\n",
    "        logistic_ridge.fit(trainWbcd[predictors],trainWbcd['Diagnosis'])\n",
    "        logistic_ridge_predict = logistic_ridge.predict(testWbcd[predictors])\n",
    "        print(('L2 Accuracy: {}').format(accuracy_score(testWbcd['Diagnosis'],logistic_ridge_predict)))\n",
    "        print(('L2 Precision: {}').format(precision_score(testWbcd['Diagnosis'],logistic_ridge_predict,average='macro')))\n",
    "        print('L2 Confusion Matrix:')\n",
    "        print(confusion_matrix(testWbcd['Diagnosis'],logistic_ridge_predict))\n",
    "        coef = logistic_ridge.coef_\n",
    "        desc_coef = -np.sort(-coef)\n",
    "        print(('The best feature is: {}').format(predictors[(np.where(coef==desc_coef[:,0]))[1][0]]))\n",
    "        print(('The 2nd best feature is: {}').format(predictors[(np.where(coef==desc_coef[:,1]))[1][0]]))\n",
    "        print(('The 3rd best feature is: {}').format(predictors[(np.where(coef==desc_coef[:,2]))[1][0]]))\n",
    "        print(('The 4th best feature is: {}').format(predictors[(np.where(coef==desc_coef[:,3]))[1][0]]))\n",
    "        print(('The 5th best feature is: {}').format(predictors[(np.where(coef==desc_coef[:,4]))[1][0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective 3: Discuss if there is any sign of underfitting or overfitting with appropriate reasoning.**\n",
    "\n",
    "Overfitting and underfitting are performance issues in machine learning. It's important to consider whether the model is able to work with new data, as well as, with the data it was trained on. \n",
    "\n",
    "Overfitting occurs when the model learns the details and the noise. For both lasso (L1) and ridge (L2) logistic regression, my model performs fairly well (accuracies of 80% and 85%, respectively) on unseen data. Hence overfitting is not an issue here. \n",
    "\n",
    "Underfitting occurs when the model doesn't performn well on new data or on the data it was trained on. Since my L1 and L2 models perform well on unseen data, underfitting is not an issue here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Multiclass Classification\n",
    "### 2.1: Read and understand the data, create a default One-vs-Rest Classifier\n",
    "Objectives:\n",
    "1. Read data from the provided csv file. Print the following information:\n",
    "    * Number of data points\n",
    "    * Total number of features\n",
    "    * Unique labels in the data\n",
    "2. Split the data into 70% training data and 30% test data. Fit a One-vs-Rest Classifier (which uses Logistic regression classifier with alpha=1) on training data, and report accuracy, precision, recall on testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points: 1978200\n",
      "Total number of features: 784\n",
      "Unique labels in the data: 10\n"
     ]
    }
   ],
   "source": [
    "# Objective 1: Read data from the csv file provided and print number of data points, number of features and unique labels\n",
    "\n",
    "data = pd.read_csv('reduced_mnist.csv',delimiter=\",\",header=0)\n",
    "\n",
    "print('Number of data points: {}'.format(data.shape[0]*data.shape[1]))\n",
    "print('Total number of features: {}'.format(data.shape[1]-1))\n",
    "print('Unique labels in the data: {}'.format(data['label'].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.832010582010582\n",
      "Precision: 0.8298588013919319\n",
      "Recall: 0.8284788830209118\n"
     ]
    }
   ],
   "source": [
    "# Objective 2: Split the data into 70% training data and 30% test data. Fit a One-vs-Rest Classifier (which uses Logistic regression classifier with alpha=1) on training data, and report accuracy, precision, recall on testing data.\n",
    "\n",
    "trainData, testData = train_test_split(data,test_size=0.3)\n",
    "alpha_val = 1\n",
    "classifier = OneVsRestClassifier(LogisticRegression(penalty='l1',C=1/alpha_val))\n",
    "classifier.fit(trainData.drop(['label'],axis=1),trainData['label'])\n",
    "prediction = classifier.predict(testData.drop(['label'],axis=1))\n",
    "print('Accuracy: {}'.format(accuracy_score(testData['label'],prediction)))\n",
    "print('Precision: {}'.format(precision_score(testData['label'],prediction,average='macro')))\n",
    "print('Recall: {}'.format(recall_score(testData['label'],prediction,average='macro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2: Choosing the best hyper-parameter\n",
    "Objectives:\n",
    "\n",
    "1. As in section **1.3** above, now create 10 random splits of training data into training and validation data. Choose the best value of alpha from the following set: {0.1, 1, 3, 10, 33, 100, 333, 1000, 3333, 10000, 33333}.\n",
    "    * For each value of hyperparameter, perform 10 random splits of training data into training and validation data as said above. \n",
    "    * For each value of hyperparameter, use its 10 random splits and find the average training and validation accuracy.\n",
    "    * On a graph, plot both the average training accuracy (in red) and average validation accuracy (in blue) w.r.t. each hyperparameter setting. Comment on this graph by identifying regions of overfitting and underfitting. \n",
    "    * Print the best value of alpha hyperparameter.\n",
    "    \n",
    "    \n",
    "2. Evaluate the prediction performance on test data and report the following:\n",
    "\n",
    "    * Total number of non-zero features in the final model.\n",
    "    * The confusion matrix\n",
    "    * Precision, recall and accuracy for each class.\n",
    "    \n",
    "    \n",
    "3. Discuss if there is any sign of underfitting or overfitting with appropriate reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best value of the hyperparameter is: 333\n"
     ]
    }
   ],
   "source": [
    "# Objective 1: As in section **1.3** above, now create 10 random splits of training data into training and validation data. Choose the best value of alpha from the following set: {0.1, 1, 3, 10, 33, 100, 333, 1000, 3333, 10000, 33333}.\n",
    "\n",
    "alpha_vals = [0.1, 1, 3, 10, 33, 100, 333, 1000, 3333, 10000, 33333]\n",
    "predictors = list(trainData.drop('label',axis=1).columns.values)\n",
    "model_acc = 0\n",
    "train_acc = 0\n",
    "l1_model_acc=np.empty((len(alpha_vals),0))\n",
    "l1_train_acc=np.empty((len(alpha_vals),0))\n",
    "for a in alpha_vals:\n",
    "    for i in range(0,10):\n",
    "        train,test=train_test_split(data,test_size=0.3)\n",
    "        classifier = OneVsRestClassifier(LogisticRegression(penalty='l1',C=1/a))\n",
    "        classifier.fit(train.drop(['label'],axis=1),train['label'])\n",
    "        selfPrediction = classifier.predict(train.drop(['label'],axis=1))\n",
    "        selfPrediction = np.reshape(selfPrediction,np.shape(train['label']))\n",
    "        prediction = classifier.predict(test.drop(['label'],axis=1))\n",
    "        prediction = np.reshape(prediction,np.shape(test['label']))\n",
    "        model_acc += accuracy_score(test['label'].values.reshape((test['label'].shape[0],)),prediction)\n",
    "        train_acc += accuracy_score(train['label'].values.reshape((train['label'].shape[0],)),selfPrediction)\n",
    "    model_acc /= 10\n",
    "    train_acc /= 10\n",
    "    l1_model_acc=np.append(l1_model_acc,model_acc)\n",
    "    if train_acc > 1.0:\n",
    "        train_acc = 1.0\n",
    "        l1_train_acc=np.append(l1_train_acc,train_acc)\n",
    "    else:\n",
    "        l1_train_acc=np.append(l1_train_acc,train_acc)\n",
    "\n",
    "plt.plot(range(0,len(alpha_vals)), l1_model_acc, color='b', label='Validation Accuracy')\n",
    "plt.plot(range(0,len(alpha_vals)), l1_train_acc, color='r', label='Training Accuracy')\n",
    "plt.xticks(range(0,len(alpha_vals)), alpha_vals, rotation='vertical')\n",
    "plt.title('Training Vs Validation Accuracy')\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0, 1.0])\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()\n",
    "\n",
    "print('The best value of the hyperparameter is: {}'.format(alpha_vals[np.argmax(l1_model_acc)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comments on the graph 'Training Vs Validation Accuracy'**\n",
    "\n",
    "Overfitting occurs when the model learns the details and the noise. In the graph above, the region of overfitting occurs when the model does not perform well on unseen data even though it performs really well on training data. For my model, alpha values of 0.1 and 1 can be deemed as regions of overfitting. \n",
    "\n",
    "Underfitting occurs when the model doesn't performn well on new data or on the data it was trained on. The region of underfitting occurs when the model does not perform well on either unseen data or the training data. For my model, alpha values of 3333, 10000 and 33333 cause underfitting.  \n",
    "\n",
    "My model serves to highlight that cross-validation is invaluable for overfitting or underfitting. This is widely known across the industry and in academia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of non-zero features: 378\n",
      "Confusion Matrix:\n",
      "[[79  0  0  1  0  0  1  0  1  0]\n",
      " [ 0 77  1  1  0  0  0  0  1  0]\n",
      " [ 1  2 76  0  1  1  4  1  8  0]\n",
      " [ 0  1  3 70  0  3  1  0  1  2]\n",
      " [ 1  1  0  0 55  0  1  0  2  7]\n",
      " [ 1  1  0  4  2 39  0  0  6  1]\n",
      " [ 3  1  1  0  1  0 68  0  0  0]\n",
      " [ 1  2  4  1  2  0  0 63  1  4]\n",
      " [ 0  5  1  3  1  4  1  0 57  1]\n",
      " [ 3  0  0  0  5  0  0  2  4 59]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Class 0       0.89      0.96      0.92        82\n",
      "    Class 1       0.86      0.96      0.91        80\n",
      "    Class 2       0.88      0.81      0.84        94\n",
      "    Class 3       0.88      0.86      0.87        81\n",
      "    Class 4       0.82      0.82      0.82        67\n",
      "    Class 5       0.83      0.72      0.77        54\n",
      "    Class 6       0.89      0.92      0.91        74\n",
      "    Class 7       0.95      0.81      0.88        78\n",
      "    Class 8       0.70      0.78      0.74        73\n",
      "    Class 9       0.80      0.81      0.80        73\n",
      "\n",
      "avg / total       0.85      0.85      0.85       756\n",
      "\n",
      "Accuracy of Class 0: 0.98\n",
      "Accuracy of Class 1: 0.98\n",
      "Accuracy of Class 2: 0.96\n",
      "Accuracy of Class 3: 0.97\n",
      "Accuracy of Class 4: 0.96\n",
      "Accuracy of Class 5: 0.97\n",
      "Accuracy of Class 6: 0.98\n",
      "Accuracy of Class 7: 0.97\n",
      "Accuracy of Class 8: 0.94\n",
      "Accuracy of Class 9: 0.96\n"
     ]
    }
   ],
   "source": [
    "# Objective 2: Evaluate the prediction performance on test data and report the requisite evaluation metrics\n",
    "\n",
    "max_index_l1 = np.argmax(l1_model_acc)\n",
    "best_alpha = alpha_vals[max_index_l1]\n",
    "classifier = OneVsRestClassifier(LogisticRegression(penalty='l1',C=1/best_alpha))\n",
    "classifier.fit(trainData.drop(['label'],axis=1),trainData['label'])\n",
    "classifier_predict = classifier.predict(testData.drop(['label'],axis=1))\n",
    "\n",
    "feature_coef = 0\n",
    "count_nonzero = 0\n",
    "for j in range(0,784):\n",
    "    for i in range(0,10):\n",
    "        feature_coef += classifier.estimators_[i].coef_[:,j]\n",
    "    if feature_coef != 0:\n",
    "        count_nonzero += 1\n",
    "    feature_coef = 0\n",
    "\n",
    "print('Total number of non-zero features: {}'.format(count_nonzero))\n",
    "confusionMatrix = confusion_matrix(testData['label'],classifier_predict)\n",
    "\n",
    "diagonalOfConfusionMatrix = np.diagonal(confusionMatrix)\n",
    "print('Confusion Matrix:')\n",
    "print(confusionMatrix)\n",
    "\n",
    "target_names=['Class 0','Class 1','Class 2','Class 3','Class 4','Class 5','Class 6','Class 7','Class 8','Class 9']\n",
    "print(classification_report(testData['label'],classifier_predict,target_names=target_names))\n",
    "\n",
    "for i in range(0,10):\n",
    "    print(('Accuracy of Class '+str(i)+': {}').format(round(np.sum(diagonalOfConfusionMatrix)/(np.sum(confusionMatrix[i])+np.sum(confusionMatrix[:,i])-(2*diagonalOfConfusionMatrix[i])+np.sum(diagonalOfConfusionMatrix)),2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective 3: Discuss if there is any sign of underfitting or overfitting with appropriate reasoning**\n",
    "\n",
    "My model does not show any signs of overfitting or underfitting. \n",
    "\n",
    "Overfitting occurs when the model learns the details and the noise. In my model, the prediction accuracies for each class are greater than 95% and the overall model accuracy is over 80%. This shows that my model has performed well on data that it had not seen prior to learning.\n",
    "\n",
    "Underfitting occurs when the model doesn't performn well on new data or on the data it was trained on. In my model, the training accuracy for the best alpha value is over 100% (see graph 'Training Vs Validation Accuracy') and the accuracy on the test data is over 80%. This shows that my model performs well on data it was trained on, whilst also performing well on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div style=\"text-align: center\">**END OF ASSIGNMENT TWO**</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
